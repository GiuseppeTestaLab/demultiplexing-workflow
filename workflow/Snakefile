#!/usr/bin/env python

# import statements of necessary modules
import getpass    # Portable password input (here used for access to usernames)
import os         # Miscellaneous operating system interfaces
import yaml       # YAML parser and emitter for Python
import shutil     # High-level file operations
import snakemake  # Workflow management system

# write files with g+rwX permissions
os.umask(2)

###########################################################################

# input operations: read input file and config file,
#                   define list of files to process

# validate config with the yaml schema
snakemake.utils.validate(config, "schemas/config.schema.yaml")

# read the yaml input file and store its content in the inputdata dictionary
with open(config["inputfile"]) as f:
    inputdata = yaml.full_load(f)
# snakemake.utils.validate(inputdata, "schemas/input.schema.yaml")

###########################################################################

# preliminary actions: path and file definitions

# define the reference files and dir, by extracting the information from the config file
reference_label = inputdata["ref"]
genome_file = config["reference_files"][reference_label]["genome"]

# get the username and possibly map it using the dictionary in config.yaml file
username = getpass.getuser()
if username in config["userid_map"]:
    username = config["userid_map"][username]

# define directory where results will be stored... paths have the following structure:
# {datapath}/SNPcall/{type of data}/{project}-{reference}/{user}
set_id = "{0}-{1}".format(inputdata["project"], reference_label)
demultiplexing_path = os.path.join(config["datapath"],"scRNAseq", "demultiplexing", set_id, username)
report_path = os.path.join(config["datapath"], "scRNAseq", "reports", set_id, username)
benchmark_path = os.path.join(config["datapath"], "scRNAseq", "benchmarks", set_id, username)
# the following is a temporary path where intermediate BAM files are written
processing_path = os.path.join(config["datapath"], "scRNAseq", "tmp_" + set_id + "_" + username)


# define list of final count files
sample_list = list(inputdata["samples"].keys())
demult_files = []
for sample in sample_list:
    demult_files.append(os.path.join(demultiplexing_path, sample, 'demuxlet_v1', '{}.best'.format(sample)))
    demult_files.append(os.path.join(demultiplexing_path, sample, 'demuxlet_v2', '{}.best'.format(sample)))
    demult_files.append(os.path.join(demultiplexing_path, sample, 'vireo', 'vireo_out', 'donor_ids.tsv'))
    demult_files.append(os.path.join(demultiplexing_path, sample, 'souporcell', 'clusters.tsv'))
    demult_files.append(os.path.join(demultiplexing_path, sample, 'scansnp', 'Cell_IDs.tsv'))
    #demult_files.append(os.path.join(report_path, sample + '_demultiplexing.html'))

###########################################################################

# common parameters

_SINGULARITY_IMAGE = "docker://testalab/demultiplexing:1.4.0"

localrules: souporcell_container

###########################################################################

rule all:
    input:
        demult_files

onsuccess:
    print("Workflow completed with no error!")
    if not inputdata["debug"]:
        print("Removing temporary files from directory {}".format(processing_path))
        shutil.rmtree(processing_path, ignore_errors=True)

###########################################################################

rule demuxlet_v1:
    input:
        bam = lambda wildcards: inputdata['samples'][wildcards.sample]['bamfile'],
        vcf = lambda wildcards: inputdata['samples'][wildcards.sample]['vcf'],
        barcodes = lambda wildcards: inputdata['samples'][wildcards.sample]['barcodes']
    output:
        out = os.path.join(demultiplexing_path, '{sample}', 'demuxlet_v1', '{sample}.best')
    container: _SINGULARITY_IMAGE
    threads: 1
    resources:
        time = "18:00:00",
        mem = "32G"
    log:
        os.path.join(demultiplexing_path, "{sample}", "demuxlet_v1.log")
    benchmark:
        os.path.join(benchmark_path, "demuxlet_v1.{sample}.txt")
    params:
        barcodes_ext = lambda wildcards, input: os.path.splitext(str(input.barcodes))[1],
        outdir = lambda wildcards, output: os.path.dirname(output.out),
        scratch_dir = config["scratchpath"],
        field = lambda wildcards: inputdata['samples'][wildcards.sample]['field']
    shell:
        """
        # copy and unzip, if needed, the file with the cell barcodes 
        TMPFILE=$(mktemp {params.scratch_dir}/$USER-XXXXXX-barcodes.tsv)
        if [ {params.barcodes_ext} = ".tsv" ]; then
            cat {input.barcodes} > $TMPFILE
        elif [ {params.barcodes_ext} = ".gz" ]; then
            zcat {input.barcodes} > $TMPFILE
        fi
        
        # compute the number of cells and a required parameter
        NCELLS=`cat $TMPFILE | wc -l`
        DBLPRIOR=`python -c "print('%.3f' % ($NCELLS/13000.))"`
        echo $DBLPRIOR > {params.outdir}/dbl_prior.txt

        # run demuxlet
        demuxlet --sam {input.bam} \
                 --vcf {input.vcf} \
                 --field {params.field} \
                 --out {params.outdir}/{wildcards.sample} \
                 --group-list <( cat $TMPFILE ) \
                 --doublet-prior $DBLPRIOR >& {log}
                 
        # remove temporary file
        rm $TMPFILE
        """

###########################################################################

rule demuxlet_v2:
    input:
        bam = lambda wildcards: inputdata['samples'][wildcards.sample]['bamfile'],
        vcf = lambda wildcards: inputdata['samples'][wildcards.sample]['vcf'],
        barcodes = lambda wildcards: inputdata['samples'][wildcards.sample]['barcodes']
    output:
        out = os.path.join(demultiplexing_path, '{sample}', 'demuxlet_v2', '{sample}.best')
    container: _SINGULARITY_IMAGE
    threads: 1
    resources:
        time = "18:00:00",
        mem = "32G"
    log:
        os.path.join(demultiplexing_path, "{sample}", "demuxlet_v2.log")
    benchmark:
        os.path.join(benchmark_path, "demuxlet_v2.{sample}.txt")
    params:
        barcodes_ext = lambda wildcards, input: os.path.splitext(str(input.barcodes))[1],
        outdir = lambda wildcards, output: os.path.dirname(output.out),
        scratch_dir = config["scratchpath"],
        field = lambda wildcards: inputdata['samples'][wildcards.sample]['field']
    shell:
        """
        # copy and unzip, if needed, the file with the cell barcodes 
        TMPFILE=$(mktemp {params.scratch_dir}/$USER-XXXXXX-barcodes.tsv)
        if [ {params.barcodes_ext} = ".tsv" ]; then
            cat {input.barcodes} > $TMPFILE
        elif [ {params.barcodes_ext} = ".gz" ]; then
            zcat {input.barcodes} > $TMPFILE
        fi
        
        # compute the number of cells and a required parameter
        NCELLS=`cat $TMPFILE | wc -l`
        DBLPRIOR=`python -c "print('%.3f' % ($NCELLS/13000.))"`
        echo $DBLPRIOR > {params.outdir}/dbl_prior.txt

        # run demuxlet
        popscle demuxlet --sam {input.bam} \
                         --vcf {input.vcf} \
                         --out {params.outdir}/{wildcards.sample} \
                         --field {params.field} \
                         --group-list $TMPFILE \
                         --doublet-prior $DBLPRIOR >& {log}
                 
        # remove temporary file
        rm $TMPFILE                         
        """

###########################################################################

rule cellsnp:
    input:
        bam = lambda wildcards: inputdata['samples'][wildcards.sample]['bamfile'],
        vcf = lambda wildcards: inputdata['samples'][wildcards.sample]['vcf'],
        barcodes = lambda wildcards: inputdata['samples'][wildcards.sample]['barcodes']
    output:
        out = os.path.join(demultiplexing_path, "{sample}", 'vireo', 'cellSNP_out', 'cellSNP.samples.tsv')
    container: _SINGULARITY_IMAGE
    threads: 10
    resources:
        time = "18:00:00",
        mem = "32G"
    log:
        os.path.join(demultiplexing_path, "{sample}", "vireo_1.log")
    benchmark:
        os.path.join(benchmark_path,"vireo.{sample}.txt")
    params:
        barcodes_ext = lambda wildcards, input: os.path.splitext(str(input.barcodes))[1],
        outdir = lambda wildcards, output: os.path.dirname(output.out),
        scratch_dir = config["scratchpath"]
    shell:
        """
        # copy and unzip, if needed, the file with the cell barcodes 
        TMPFILE=$(mktemp {params.scratch_dir}/$USER-XXXXXX-barcodes.tsv)
        if [ {params.barcodes_ext} = ".tsv" ]; then
            cat {input.barcodes} > $TMPFILE
        elif [ {params.barcodes_ext} = ".gz" ]; then
            zcat {input.barcodes} > $TMPFILE
        fi

        # run cellSNP
        cellSNP -s {input.bam} \
                -b $TMPFILE \
                -O {params.outdir} \
                -R {input.vcf} \
                -p {threads} \
                --minMAF 0.1 \
                --minCOUNT 20 >& {log}

        # remove temporary file
        rm $TMPFILE               
        """

###########################################################################

rule vireo:
    input:
        vcf = lambda wildcards: inputdata['samples'][wildcards.sample]['vcf'],
        cellsnp = os.path.join(demultiplexing_path, "{sample}", 'vireo', 'cellSNP_out', 'cellSNP.samples.tsv')
    output:
        out = os.path.join(demultiplexing_path, "{sample}", 'vireo', 'vireo_out', 'donor_ids.tsv')
    container: _SINGULARITY_IMAGE
    threads: 10
    resources:
        time = "18:00:00",
        mem = "32G"
    log:
        os.path.join(demultiplexing_path,"{sample}","vireo_2.log")
    benchmark:
        os.path.join(benchmark_path,"vireo.{sample}.txt")
    params:
        indir = lambda wildcards, input: os.path.dirname(input.cellsnp),
        genotag = lambda wildcards: inputdata['samples'][wildcards.sample]['field'],
        outdir = lambda wildcards, output: os.path.dirname(output.out)
    shell:
        """
        # run vireo
        vireo  -c {params.indir} \
               -d <(grep -v '\.\/\.' {input.vcf}) \
               --genoTag {params.genotag} \
               -o {params.outdir} >> {log} 2>&1
        """

###########################################################################

rule souporcell_container:
    output:
        sif = os.path.join(processing_path, "souporcell.sif")
    params:
        outdir = lambda wildcards, output: os.path.dirname(output.sif)
    shell:
        """
        # move to the path where the image file will be saved
        cd {params.outdir}
        # download the file
        CONFIRM=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate \
                  'https://docs.google.com/uc?export=download&id=1tj2j8QZuGz8sylHgWbnejWyUn8n6m0Y8' -O- \
                  | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')
        wget --quiet --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$CONFIRM&id=1tj2j8QZuGz8sylHgWbnejWyUn8n6m0Y8" -O souporcell.sif 
        rm -rf /tmp/cookies.txt
        """

###########################################################################

rule souporcell:
    input:
        bam = lambda wildcards: inputdata['samples'][wildcards.sample]['bamfile'],
        vcf = lambda wildcards: inputdata['samples'][wildcards.sample]['vcf'],
        barcodes = lambda wildcards: inputdata['samples'][wildcards.sample]['barcodes'],
        fasta = genome_file,
        sif = os.path.join(processing_path, "souporcell.sif")
    output:
        out = os.path.join(demultiplexing_path, "{sample}", 'souporcell', 'clusters.tsv')
    container: os.path.join(processing_path, "souporcell.sif")
    threads: 10
    resources:
        time="18:00:00",
        mem="32G"
    log:
        os.path.join(demultiplexing_path,"{sample}","souporcell.log")
    benchmark:
        os.path.join(benchmark_path,"souporcell.{sample}.txt")
    params:
        barcodes_ext = lambda wildcards, input: os.path.splitext(str(input.barcodes))[1],
        ngenotypes = lambda wildcards: inputdata['samples'][wildcards.sample]['ngenotypes'],
        outdir = lambda wildcards, output: os.path.dirname(output.out),
        genotag=lambda wildcards: inputdata['samples'][wildcards.sample]['field'],
        scratch_dir=config["scratchpath"]
    shell:
        """
        # copy and unzip, if needed, the file with the cell barcodes 
        TMPFILE=$(mktemp {params.scratch_dir}/$USER-XXXXXX-barcodes.tsv)
        if [ {params.barcodes_ext} = ".tsv" ]; then
            cat {input.barcodes} > $TMPFILE
        elif [ {params.barcodes_ext} = ".gz" ]; then
            zcat {input.barcodes} > $TMPFILE
        fi

        # run souporcell
        souporcell_pipeline.py \
            -i {input.bam} \
            -b $TMPFILE \
            -f {input.fasta} \
            -t {threads} \
            -o {params.outdir} \
            -k {params.ngenotypes} >& {log}
                    
        # remove temporary file
        rm $TMPFILE
        """

###########################################################################


# ---Singularity container is hardcoded, need to include scDBlfinder in final image

# rule scDblFinder:
# 	output:
#		barcodesclass = os.path.join(demultiplexing_path, "{sample}", 'scdblfinder', 'barcodesclass.tsv')
# 	singularity:
# 		/hpcnfs/data/GT/singularityImages/organoidMultiplexing_Downstream_2.0.sif
#	log:
#		os.path.join(demultiplexing_path,"{sample}","scdblfinder.log")
# 	params:
# 		filtered_matrix = lambda wildcards: inputdata['samples'][wildcards.sample]['filteredmatrix'],
# 	script:
# 		"scripts/scDBLfinder.R"

###########################################################################

rule scansnp:
    input:
        bam = lambda wildcards: inputdata['samples'][wildcards.sample]['bamfile'],
        vcf = lambda wildcards: inputdata['samples'][wildcards.sample]['vcf'],
        barcodes = lambda wildcards: inputdata['samples'][wildcards.sample]['barcodes']
    output:
        barcodesid = os.path.join(demultiplexing_path, "{sample}", 'scansnp', 'Cell_IDs.tsv')
    container: _SINGULARITY_IMAGE
    threads: 10
    resources:
        time = "24:00:00",
        mem = "48G"
    log:
        os.path.join(demultiplexing_path,"{sample}","scansnp.log")
    benchmark:
        os.path.join(benchmark_path,"scansnp.{sample}.txt")
    params:
        outdir = lambda wildcards, output: os.path.dirname(output.barcodesid),
        scratch_dir = config["scratchpath"]
    shell:
        """
        # activate conda environment with SCanSNP requirements, saving the env options to file
        TMPFILE=$(mktemp {params.scratch_dir}/$USER-XXXXXX-activate_conda.sh)
        conda shell.zsh hook > $TMPFILE
        set +u; source $TMPFILE; conda activate scansnp; set -u
        # run SCanSNP
        python /usr/local/SCanSNP/SCanSNP/SCanSNP.py \
               --threads {threads} \
               --bam {input.bam} \
               --barcodes {input.barcodes} \
               --vcf {input.vcf} \
               --outdir {params.outdir} >& {log}
        # clean up conda file
        rm $TMPFILE
        """

###########################################################################

rule sample_report:
    input:
        demuxlet_v1 = os.path.join(demultiplexing_path,'{sample}','demuxlet_v1','{sample}.best'),
        demuxlet_v2 = os.path.join(demultiplexing_path,'{sample}','demuxlet_v2','{sample}.best'),
        soc = os.path.join(demultiplexing_path, "{sample}", 'souporcell', 'clusters.tsv'),
        vireo = os.path.join(demultiplexing_path, "{sample}", 'vireo', 'vireo_out', 'donor_ids.tsv'),
        scansnp = os.path.join(demultiplexing_path, "{sample}", 'scansnp', 'Cell_IDs.tsv')
    output:
        html =  os.path.join(report_path, "{sample}" + '_demultiplexing.html')
    container: _SINGULARITY_IMAGE
    threads: 1
    resources:
        time = "6:00:00",
        mem = "4G"
    log:
        os.path.join(report_path, "{sample}", "sample_report.log")
    params:
        dataset = lambda wildcards: wildcards.sample,
        filtered_matrix = lambda wildcards: inputdata['samples'][wildcards.sample]['filteredmatrix'],
        barcode_map = lambda wildcards: inputdata['samples'][wildcards.sample]['referencecall'],
        demult_metrics = os.path.join(report_path, "{sample}", 'demultiplexing_metrics.tsv'),
        combined_results = os.path.join(report_path, "{sample}", 'combined_calls.tsv')
    script:
        "scripts/Demultiplexing_report.Rmd"

###########################################################################

sample_demult_files = []
for sample in sample_list:
    sample_demult_files.append(os.path.join(report_path, sample + '_demultiplexing.html'))

rule aggregated_report:
    input:
        results_file = sample_demult_files
    output:
        html = os.path.join(report_path, 'demultiplexing_aggregated.html')
    container: _SINGULARITY_IMAGE
    threads: 1
    resources:
        time = "6:00:00",
        mem = "4G"
    params:
        sample_names = sample_list
    script:
        "scripts/Demultiplexing_aggregation.Rmd"
