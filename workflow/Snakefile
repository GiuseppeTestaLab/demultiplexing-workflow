#!/usr/bin/env python

# import statements of necessary modules
import getpass    # Portable password input (here used for access to usernames)
import os         # Miscellaneous operating system interfaces
import yaml       # YAML parser and emitter for Python
# import snakemake  # Workflow management system

# write files with g+rwX permissions
os.umask(2)

###########################################################################

# input operations: read input file and config file,
#                   define list of files to process

# validate config with the yaml schema
# snakemake.utils.validate(config, "schemas/config.schema.yaml")

# read the yaml input file and store its content in the inputdata dictionary
with open(config["inputfile"]) as f:
    inputdata = yaml.full_load(f)
# snakemake.utils.validate(inputdata, "schemas/input.schema.yaml")

###########################################################################

# preliminary actions: path and file definitions

# define the reference files and dir, by extracting the information from the config file
reference_label = inputdata["ref"]
genome_file = config["reference_files"][reference_label]["genome"]

# get the username and possibly map it using the dictionary in config.yaml file
username = getpass.getuser()
if username in config["userid_map"]:
    username = config["userid_map"][username]

# define directory where results will be stored... paths have the following structure:
# {datapath}/SNPcall/{type of data}/{project}-{reference}/{user}
set_id = "{0}-{1}".format(inputdata["project"], reference_label)
demultiplexing_path = os.path.join(config["datapath"],"scRNAseq", "demultiplexing", set_id, username)
report_path = os.path.join(config["datapath"], "scRNAseq", "reports", set_id, username)
benchmark_path = os.path.join(config["datapath"], "scRNAseq", "benchmarks", set_id, username)
# the following is a temporary path where intermediate BAM files are written
processing_path = os.path.join(config["datapath"], "scRNAseq", "tmp_" + set_id + "_" + username)

# define list of final count files
sample_list = list(inputdata["samples"].keys())
demult_files = []
for sample in sample_list:
    demult_files.append(os.path.join(demultiplexing_path, sample, 'demuxlet_v1', '{}.best'.format(sample)))
    demult_files.append(os.path.join(demultiplexing_path, sample, 'demuxlet_v2', '{}.best'.format(sample)))
    demult_files.append(os.path.join(demultiplexing_path, sample, 'vireo', 'vireo_out' 'donor_ids.tsv'))
#   expand( WD + '{sample}/SoupOrCell/clusters.tsv', sample = NAMES),
#   expand( WD + '{sample}/Demultiplexing.report.html',sample = NAMES),


###########################################################################

# common parameters

_SINGULARITY_IMAGE = "docker://testalab/demultiplexing:1.1.0"

###########################################################################

rule all:
    input:
        demult_files#, multiqc_out = os.path.join(report_path, 'demultiplexing', 'report.html')

###########################################################################

rule demuxlet_v1:
    input:
        bam = lambda wildcards: inputdata['samples'][wildcards.sample]['bamfile'],
        vcf = lambda wildcards: inputdata['samples'][wildcards.sample]['vcf'],
        barcodes = lambda wildcards: inputdata['samples'][wildcards.sample]['barcodes']
    output:
        out = os.path.join(demultiplexing_path, '{sample}', 'demuxlet_v1', '{sample}.best')
    container: _SINGULARITY_IMAGE
    threads: 1
    resources:
        time = "18:00:00",
        mem = "32G"
    log:
        os.path.join(demultiplexing_path, "{sample}", "demuxlet_v1.log")
    benchmark:
        os.path.join(benchmark_path, "demuxlet_v1.{sample}.txt")
    params:
        barcodes_ext = lambda wildcards, input: os.path.splitext(str(input.barcodes))[1],
        outdir = lambda wildcards, output: os.path.dirname(output.out),
        scratch_dir = config["scratchpath"],
        field = lambda wildcards: inputdata['samples'][wildcards.sample]['field']
    shell:
        """
        # copy and unzip, if needed, the file with the cell barcodes 
        TMPFILE=$(mktemp {params.scratch_dir}/$USER-XXXXXX-barcodes.tsv)
        if [ {params.barcodes_ext} = ".tsv" ]; then
            cat {input.barcodes} > $TMPFILE
        elif [ {params.barcodes_ext} = ".gz" ]; then
            zcat {input.barcodes} > $TMPFILE
        fi
        
        # compute the number of cells and a required parameter
        NCELLS=`cat $TMPFILE | wc -l`
        DBLPRIOR=`python -c "print('%.3f' % ($NCELLS/13000.))"`
        echo $DBLPRIOR > {params.outdir}/dbl_prior.txt

        # run demuxlet
        demuxlet --sam {input.bam} \
                 --vcf {input.vcf} \
                 --field {params.field} \
                 --out {params.outdir}/{wildcards.sample} \
                 --group-list <( cat $TMPFILE ) \
                 --doublet-prior $DBLPRIOR >& {log}
                 
        # remove temporary file
        rm $TMPFILE
        """

###########################################################################

rule demuxlet_v2:
    input:
        bam = lambda wildcards: inputdata['samples'][wildcards.sample]['bamfile'],
        vcf = lambda wildcards: inputdata['samples'][wildcards.sample]['vcf'],
        barcodes = lambda wildcards: inputdata['samples'][wildcards.sample]['barcodes']
    output:
        out = os.path.join(demultiplexing_path, '{sample}', 'demuxlet_v2', '{sample}.best')
    container: _SINGULARITY_IMAGE
    threads: 1
    resources:
        time = "18:00:00",
        mem = "32G"
    log:
        os.path.join(demultiplexing_path, "{sample}", "demuxlet_v2.log")
    benchmark:
        os.path.join(benchmark_path, "demuxlet_v2.{sample}.txt")
    params:
        barcodes_ext = lambda wildcards, input: os.path.splitext(str(input.barcodes))[1],
        outdir = lambda wildcards, output: os.path.dirname(output.out),
        scratch_dir = config["scratchpath"],
        field = lambda wildcards: inputdata['samples'][wildcards.sample]['field']
    shell:
        """
        # copy and unzip, if needed, the file with the cell barcodes 
        TMPFILE=$(mktemp {params.scratch_dir}/$USER-XXXXXX-barcodes.tsv)
        if [ {params.barcodes_ext} = ".tsv" ]; then
            cat {input.barcodes} > $TMPFILE
        elif [ {params.barcodes_ext} = ".gz" ]; then
            zcat {input.barcodes} > $TMPFILE
        fi
        
        # compute the number of cells and a required parameter
        NCELLS=`cat $TMPFILE | wc -l`
        DBLPRIOR=`python -c "print('%.3f' % ($NCELLS/13000.))"`
        echo $DBLPRIOR > {params.outdir}/dbl_prior.txt

        # run demuxlet
        popscle demuxlet --sam {input.bam} \
                         --vcf {input.vcf} \
                         --out {params.outdir}/{wildcards.sample} \
                         --field {params.field} \
                         --group-list $TMPFILE \
                         --doublet-prior $DBLPRIOR >& {log}
                 
        # remove temporary file
        rm $TMPFILE                         
        """

###########################################################################

rule vireo:
    input:
        bam = lambda wildcards: inputdata['samples'][wildcards.sample]['bamfile'],
        vcf = lambda wildcards: inputdata['samples'][wildcards.sample]['vcf'],
        barcodes = lambda wildcards: inputdata['samples'][wildcards.sample]['barcodes']
    output:
        out = os.path.join(demultiplexing_path,"{sample}",'vireo','vireo_out' 'donor_ids.tsv')
    container: _SINGULARITY_IMAGE
    threads: 10
    resources:
        time = "18:00:00",
        mem = "32G"
    log:
        os.path.join(demultiplexing_path,"{sample}","vireo.log")
    benchmark:
        os.path.join(benchmark_path,"vireo.{sample}.txt")
    params:
        barcodes_ext = lambda wildcards, input: os.path.splitext(str(input.barcodes))[1],
        genotag = lambda wildcards: inputdata['samples'][wildcards.sample]['field'],
        outdir = lambda wildcards, output: os.path.dirname(output.out),
        outdir_cellsnp = os.path.join(demultiplexing_path,"{sample}",'vireo','cellSNP_out'),
        scratch_dir = config["scratchpath"]
    shell:
        """
        # copy and unzip, if needed, the file with the cell barcodes 
        TMPFILE=$(mktemp {params.scratch_dir}/$USER-XXXXXX-barcodes.tsv)
        if [ {params.barcodes_ext} = ".tsv" ]; then
            cat {input.barcodes} > $TMPFILE
        elif [ {params.barcodes_ext} = ".gz" ]; then
            zcat {input.barcodes} > $TMPFILE
        fi

        # run cellSNP
        cellSNP -s {input.bam} \
                -b $TMPFILE \
                -O {params.outdir_cellsnp} \
                -R {input.vcf} \
                -p {threads} \
                --minMAF 0.1 \
                --minCOUNT 20 >& {log}
        # run vireo
        vireo  -c {params.outdir_cellsnp} \
               -d <(grep -v '\.\/\.' {input.vcf}) \
               --genoTag {params.genotag} \
               -o {params.outdir} >>& {log}

        # remove temporary file
        rm $TMPFILE               
        """

###########################################################################

####################################################### SoupOrCell  ######################################
#################################################################################################################
rule SoupOrCell:
	input:
		bampath = lambda wildcards: inputdata['MultiplexedExperiments'][wildcards.sample]['BAM'],
		vcfpath = lambda wildcards: inputdata['MultiplexedExperiments'][wildcards.sample]['VCF'],
		barcodeFile = lambda wildcards: inputdata['MultiplexedExperiments'][wildcards.sample]['goodBarcodes']
	output:
		SoC =  WD + '{sample}/SoupOrCell/clusters.tsv',
	params:
		ext= lambda wildcards: inputdata['MultiplexedExperiments'][wildcards.sample]['goodBarcodes'].split('.')[-1],
		k= lambda wildcards: inputdata['MultiplexedExperiments'][wildcards.sample]['mixedGenotypes'],
		ncpus = config['SoupOrCell']['ncpus']
	singularity:
		SOCIMAGEPATH
	log:"logs/SoupOrCell.{sample}.log"
	shell:
		"""
		exec 2>{log}
		mkdir -p {WD}{wildcards.sample}
		cd {WD}{wildcards.sample}


		if [ {params.ext} = "tsv" ]; then
		gzip -c {input.barcodeFile} > {WD}{wildcards.sample}/zippedBC_SoC.gz
		souporcell_pipeline.py \
		-i {input.bampath} \
		-b {WD}{wildcards.sample}/zippedBC_SoC.gz \
		-f {REFERENCEFASTA} \
		-t {params.ncpus} \
		-o {WD}{wildcards.sample}/SoupOrCell \
		-k {params.k} && rm {WD}{wildcards.sample}/zippedBC_SoC.gz
		elif [ {params.ext} = "gz" ]; then
		souporcell_pipeline.py \
		-i {input.bampath} \
		-b {input.barcodeFile} \
		-f {REFERENCEFASTA} \
		-t {params.ncpus} \
		-o {WD}{wildcards.sample}/SoupOrCell \
		-k {params.k}
		fi
		"""

#########################################################--Fire up SCanSNP MTRIXGEN MODE--######################################
##################################################################################################################
rule SCANSNPMATRIXGEN:
	input:
		bampath = lambda wildcards: inputdata['MultiplexedExperiments'][wildcards.sample]['BAM'],
		vcfpath = lambda wildcards: inputdata['MultiplexedExperiments'][wildcards.sample]['VCF'],
		barcodeFile = lambda wildcards: inputdata['MultiplexedExperiments'][wildcards.sample]['goodBarcodes']
	output:
		counts = WD + '{sample}/SCanSNP/Counts.npz'
	params:
		nthreads = config['SCANSNPMATRIXGEN']['ncpus']
	singularity:
		IMAGEPATH
	log:"logs/SCANSNPMATRIXGEN.{sample}.log"
	shell:
		"""
		exec 2>{log}
		mkdir -p {WD}{wildcards.sample}/SCanSNP
		cd {WD}{wildcards.sample}/SCanSNP

		python3 /softwares/SCanSNP/SCanSNP.py \
		--threads {params.nthreads} \
		--mode matrixgen \
		--BAM {input.bampath} \
		--barcodes {input.barcodeFile} \
		--vcf {input.vcfpath} \
		--outdir {WD}{wildcards.sample}/SCanSNP
		"""



#########################################################--Fire up SCanSNP DECONVOLUTION MODE--######################################
##################################################################################################################

rule SCANSNPDECONVOLUTION:
	input:
		countMatrices = WD + '{sample}/SCanSNP/Counts.npz',
		bampath = lambda wildcards: inputdata['MultiplexedExperiments'][wildcards.sample]['BAM'],
		vcfpath = lambda wildcards: inputdata['MultiplexedExperiments'][wildcards.sample]['VCF'],
	output:
		WD + '{sample}/SCanSNP/Barcode-ID.tsv',
		WD + '{sample}/SCanSNP/DBLmetricsDF.tsv'
	params:
		nthreads = config['SCANSNPDECONVOLUTION']['ncpus']
	singularity:
		IMAGEPATH
	log:"logs/SCANSNPDECONVOLUTION.{sample}.log"
	shell:
		"""
		exec 2>{log}
		mkdir -p {WD}{wildcards.sample}/SCanSNP
		cd {WD}{wildcards.sample}/SCanSNP

		python3 /softwares/SCanSNP/SCanSNP.py \
		--mode deconvolution \
		--counts {WD}{wildcards.sample}/SCanSNP \
		--vcf {input.vcfpath} \
		--outdir {WD}{wildcards.sample}/SCanSNP
		"""

# #########################################################--DBL-SNG NEGBIN model fitting--######################################
# ##################################################################################################################

rule SCANSNPDBLsMARK:
	input:
		DBLmetricsDF = WD + '{sample}/SCanSNP/DBLmetricsDF.tsv'
	output:
		WD + '{sample}/SCanSNP/doubletsMarked.tsv'
	singularity:
		IMAGEPATH
	log:"logs/MIXTUREFITTING.{sample}.log"
	shell:
		"""
		exec 2>{log}
		mkdir -p {WD}{wildcards.sample}/SCanSNP
		cd {WD}{wildcards.sample}/SCanSNP

		Rscript /softwares/SCanSNP/dblsMark.r \
		{input.DBLmetricsDF} {WD}{wildcards.sample}/SCanSNP
		"""

# #########################################################--DEMULTIPLEXINGREPORT--######################################
# ##################################################################################################################


rule DEMULTIPLEXINGREPORT:
	input:
		Demuxlet_V1 =  WD + '{sample}/Demuxlet_V1/{sample}.best',
		Demuxlet_V2 = WD + '{sample}/Demuxlet_V2/{sample}.best',
		SoC =  WD + '{sample}/SoupOrCell/clusters.tsv',
		Vireo = WD + '{sample}/Vireo/vireoOut/donor_ids.tsv',
		SCanSNP = WD + '{sample}/SCanSNP/doubletsMarked.tsv'
	output:
		htmlOut =  WD + '{sample}/Demultiplexing.report.html',
		metricesOut =  WD + '{sample}/ReportFiles/{sample}.report.tsv',
	params:
		BarcodeMap = lambda wildcards: inputdata['MultiplexedExperiments'][wildcards.sample]['barcodesMap'],
		FilteredFeaturesPath = lambda wildcards: inputdata['MultiplexedExperiments'][wildcards.sample]['FilteredFeaturesPath']
	singularity:
		IMAGEPATH
	log:"logs/DEMULTIPLEXINGREPORT.{sample}.log"
	shell:
		"""
		exec 2>{log}

		mkdir -p {WD}{wildcards.sample}/ReportFiles

Rscript -e "knitr::knit_meta(class=NULL, clean = TRUE); \
Sys.setenv("MC_CORES"=3L); \
rmarkdown::render('/scripts/Demultiplexing_report.Rmd' , \
intermediates_dir = '{WD}{wildcards.sample}/', \
output_file = '{output.htmlOut}', \
output_dir = '{WD}{wildcards.sample}/', \
params = list( Dataset = '{wildcards.sample}' , FilteredFeaturesPath =  '{params.FilteredFeaturesPath}' , Demuxlet_V1 = '{input.Demuxlet_V1}', Demuxlet_V2 = '{input.Demuxlet_V2}', SoC = '{input.SoC}', Vireo = '{input.Vireo}' , SCanSNP = '{input.SCanSNP}', BarcodeMap = '{params.BarcodeMap}', outFile = '{output.metricesOut}' ))"
		"""



rule DEMULTIPLEXINGAGGREGATION:
	input:
		MetricesList = expand(WD + '{sample}/ReportFiles/{sample}.report.tsv', sample = NAMES)
	output:
		htmlOut = WD + 'AggregatedReport/AggregatedReport.html'
	params:
		NamesList = list(NAMES)
	singularity:
		IMAGEPATH
	log:"logs/DEMULTIPLEXINGAGGREGATION.log"
	shell:
		"""
		exec 2>{log}

		mkdir -p {WD}/ReportFiles

		DMXmetrices=`echo {input.MetricesList} | sed 's/ /,/g'`
		DSnames=`echo {params.NamesList} | sed 's/ /,/g'`


Rscript -e "knitr::knit_meta(class=NULL, clean = TRUE); \
Sys.setenv("MC_CORES"=3L); \
rmarkdown::render('/scripts/Demultiplexing_aggregation.Rmd' , \
intermediates_dir = '{WD}/AggregatedReport', \
output_file = '{output.htmlOut}', \
output_dir = '{WD}/AggregatedReport', \
params = list( DSnames = '${{DSnames}}' , DMXmetrices =  '${{DMXmetrices}}'  ))"
		"""
